## 集成学习  
**集成学习的一般结构:**  先产生一组"个体学习
器" (individual learner) ，再用某种策略将它们结合起来.个体学习器通常
由一个现有的学习算法从训练数据产生，例如C4.5 决策树算法、BP 神经网
络算法等，此时集成中只包含同种类型的个体学习器，例如"决策树集成"
中全是决策树?"神经网络集成"中全是神经网络，这样的集成是"同质"
的(homogeneous) .同质集成中的个体学习器亦称"基学习器" (base learner),
相应的学习算法称为"基学习算法" (base learning algorithm). 集成也可包含
不同类型的个体学习器，例如同时包含决策树和神经网络，这样的集成是"异
质"的(heterogenous) .异质集成中的个体学习器由不同的学习算法生成，这时
就不再有基学习算法;相应的，个体学习器一般不称为基学习器，常称为"组件
学习器" (component learner) 或直接称为个体学习器.  

***
**目前的集成学习方法大致可分为两大类**：  

1.个体学习器问存在强依赖关系、必须串行生成的序列化方法；eg：**Boosting**  
2.个体学习器间不存在强依赖关系、可同时生成的并行化方法；eg：**Bagging** 和**Random Forest**.  
***注：集成学习框架中的基模型是弱模型,通常来说弱模型是偏差高（在训练集上准确度低）方差小（防止过拟合能力强）的模型。
但是，并不是所有集成学习框架中的基模型都是弱模型。bagging和stacking中的基模型为强模型（偏差低方差高），boosting中的基模型为弱模型。***  
